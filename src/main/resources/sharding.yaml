#数据源配置
dataSources:
  # 主数据库配置
  m1:
    # 数据源类名，这里使用的是阿里巴巴的Druid连接池
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    # JDBC驱动类名
    driverClassName: com.mysql.cj.jdbc.Driver
    # 数据库连接URL，包括数据库地址、端口、数据库名以及连接参数
    url: xxxx
    # 数据库登录用户名
    username: xxxx
    # 数据库登录密码
    password: xxx

# 分片规则配置
rules:
  # 分表路由配置
  - !SHARDING
    # 定义需要分片的表及其分片策略
    tables:
      t_order:
        # 定义实际的数据节点，包括数据源名称和表名
        actualDataNodes: m1.t_order_$->{1..2}
        # 定义表的分片策略
        tableStrategy:
          standard:
            # 分片键和分片算法名称
            shardingColumn: order_id
            shardingAlgorithmName: t-order-inline
        # 定义键生成策略
        keyGenerateStrategy:
          column: order_id  # 指定键生成策略的列名
          keyGeneratorName: snowflake  # 指定使用的键生成器名称 这里使用的雪花算法
      tmk_crm_common_task:
        # 定义实际的数据节点，包括数据源名称和表名
        actualDataNodes: m1.tmk_crm_common_task_5d97
        # 定义表的分片策略
        tableStrategy:
          standard:
            # 分片键和分片算法名称
            shardingColumn: scene_id
            shardingAlgorithmName: tmk-crm-common-task-inline
    # 定义分片算法
    shardingAlgorithms:
      t-order-inline:
        # 分片算法类型
        type: INLINE
        # 分片算法的属性配置
        props:
          algorithm-expression: t_order_$->{order_id % 2 + 1}  # 分片算法表达式，根据id字段的值进行取模运算
      tmk-crm-common-task-inline:
        # 分片算法类型
        type: INLINE
        # 分片算法的属性配置
        props:
          algorithm-expression: tmk_crm_common_task_$->{scene_id}  # 分片算法表达式，根据id字段的值进行取模运算

    # 定义键生成器
    keyGenerators:
      snowflake:
        # 键生成器类型
        type: SNOWFLAKE

# 其他属性配置
props:
  sql-show: true  # 是否显示执行的SQL语句，便于调试

mode:
  type: Standalone
